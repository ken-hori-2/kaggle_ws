# ** One-Hotエンコーディングについてのメモ **

今回は文字から数値に置き換える際に一つの列で置き換えた
ただ、1つの列の中で数値に置き換えると、数値の大きさに意味があるのではないかと解釈される恐れがある
例: data_all['Embarked'].replace(['S', 'C', 'Q'], [0, 1, 2])
S, C, Qはただの文字列であり、大きさや順番といった概念はないが、0~2にすると、0<2だからこの大きさや順番に意味があるのではないかとアルゴリズムが解釈する恐れがある
今回は2までなので差は小さく影響はあまりないと思われるが、10や100になってくると、その影響は看過できなくなると考えられる
そこで、One-Hotエンコーディングを使って0と1だけで値を置き換える

置き換え元のデータの種類分だけ列を作成する
S:[1,0,0], C:[0,1,0], Q:[0,0,1]
懸念点もある
データの種類分だけ新たな列が作られるため、単縦に列数がかなり増えてしまう
便利な方法だが、データサイズが増えてしまうというデメリットもある

ただ、アルゴリズムによって変わる ※LightBGMなどのアルゴリズムでは、カテゴリ(変換前の特徴量)=文字型かどうかを指定できる そうすれば、数値特有の大きさや順番を考慮しないでモデルを作ってくれるものもある

なので、One-Hotエンコーディングが必要かどうかはアルゴリズムによる
まずは使用するアルゴリズムのルール確認した上でどのように変換するかが大切
add Codeadd Markdown
モデル作成

add Codeadd Markdown
# x_test: 予測精度評価に使うデータ
#アルゴリズムに投入するため、特徴量と目的変数を分離
y_data_train = data_train['Survived']
X_data_train = data_train.drop('Survived', axis=1)
X_data_test = data_test.drop('Survived', axis=1)
​
# 説明変数と目的変数をそれぞれ　x, yとして分ける
# x:説明変数はdrop()でSurvived=答えのみ削除する
# axis=1は列を削除
​
# 教師データだけでなく、テストデータも同様にSurvived列のみ削除する
# 特徴量エンジニアリングで結合した際に、テストデータになかったSurvived列が欠損値(NaN)として作成されてしまったので、合わせて削除する
​
# y_train:答え(ラベル)
# x_train:学習に使うデータ
# x_test: 予測精度評価に使うデータ
add Codeadd Markdown
数値
#ランダムフォレストアルゴリズムをインポート
from sklearn.ensemble import RandomForestClassifier
​
clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)
​
# n_estimators: 決定木の本数(今回は100本の決定木でアンサンブルしている)
​
# max_depth: 条件をどこまで掘り下げて結果を出すか(今回は2階層分条件を分岐して結果を出す)
#   - 極端に浅いよりは深い方がいいが、必ずしも深ければ深いほどいいというわけではない
#   - なぜか？: 予測に関係ない条件も含まれることがあるため. また、処理に時間がかかる
​
# random_state: 同じ数値を指定すれば毎回実行結果が同じになる(数字はなんでもいい)
add Codeadd Markdown


# ** "ランダムフォレスト"アルゴリズムについてのメモ **

アルゴリズムとは:　数値に対して演算を行う処理をまとめたもの

言葉の定義や中身の理論は研究者以外は知らなくてもいいが、代表的なアルゴリズムにどういうものがあるか、どういう動きをするかは知っておいた方がいい
・ ランダムフォレストとは:　決定木というアルゴリズムをベースにした拡張アルゴリズム ・ 決定木： それぞれの特徴量に対して、if文のように条件分岐を設定し、真or偽の組み合わせ に応じて予測値を決定する

ランダムフォレストは決定木のアンサンブルによって精度向上を目指したアルゴリズム

アンサンブルとは: 複数の学習機を使って最終的に一つのモデルを作成する手法
日常生活において、複数人に意見を聞いた上で物事を判断するイメージ
アンサンブルもこの考え方で、複数人に聞いてから判断した方がきっと精度上がるだろうということ(例えばそれぞれの決定木が出した答えに対して多数決を取るとか)
決定木がどのような条件を辿り、予測結果を導くかはデータの構造に応じて、アルゴリズムが自動で決定していく

学習機とは　: 教師データを投入して学習を行うアルゴリズムそのものの呼び方 機械学習含めて、データサイエンスの世界では呼び方が複数あるケースが多いので、少しずつ覚えるようにする
add Codeadd Markdown
#教師データの学習
clf.fit(X_data_train, y_data_train)
​
# ポイントは説明変数と目的変数を別の引数として指定すること
add Codeadd Markdown
#作成したモデルで予測
#predictの閾値は0.5がデフォルトなので、0.5以上を1、未満を0として返す
y_data_pred = clf.predict(X_data_test)
add Codeadd Markdown
y_data_pred
add Codeadd Markdown
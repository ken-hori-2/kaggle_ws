

# Lesson4との違い

#　 ***** Lesson5での変更点 *****

# Lesson4
# params = {
# 'objective': 'binary' # 0 or 1なので
# }

# acc : 0.76
params = {
    'objective': 'binary', # 0 or 1なので
    'max_bin': 300, # 各特徴量の最大の分割数(大きすることでよりアルゴリズムの動作の幅が広がる可能性がある)
    'learning_rate': 0.05, # 小さくすることで丁寧に学習
    'num_leaves': 40 # 一つの決定木に対する分岐の末端の最大数(大きくすることでアルゴリズムの表現の幅が広がる)
}
# acc: 0.75
# params = {
#     'boosting': 'gbdt',
#     'max_bin': 300, # 各特徴量の最大の分割数(大きすることでよりアルゴリズムの動作の幅が広がる可能性がある)
#     'learning_rate': 0.05, # 小さくすることで丁寧に学習
#     'num_leaves': 40 # 一つの決定木に対する分岐の末端の最大数(大きくすることでアルゴリズムの表現の幅が広がる)
# }

#　 ***** Lesson5での変更点 *****

# MEMO
# モデルの精度を上げるためにパラメータをチューニングすることも大切だが、（最後のひと押しくらい）
# それ以上に精度に貢献するデータそのものを作り出す特徴量エンジニアリングの方が大事（時間をかけるならこっち）